{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la Ciencia de Datos: Tarea 2\n",
    "\n",
    "Este notebook contiene el código de base para realizar la Tarea 2 del curso. Puede copiarlo en su propio repositorio y trabajar sobre el mismo.\n",
    "Las **instrucciones para ejecutar el notebook** están en la [página inicial del repositorio](https://gitlab.fing.edu.uy/maestria-cdaa/intro-cd/).\n",
    "\n",
    "**Se espera que no sea necesario revisar el código para corregir la tarea**, ya que todos los resultados y análisis relevantes deberían estar en el **informe en formato PDF**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar dependencias\n",
    "Para esta tarea, se han agregado algunos requerimientos, asegúrese de instalarlos (puede usar el mismo entorno virtual de la Tarea 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jupyter in /home/luciana/.local/lib/python3.6/site-packages (1.0.0)\n",
      "Requirement already satisfied: pandas in /home/luciana/.local/lib/python3.6/site-packages (1.1.5)\n",
      "Requirement already satisfied: sqlalchemy<2.0 in /home/luciana/.local/lib/python3.6/site-packages (1.4.48)\n",
      "Requirement already satisfied: pymysql in /home/luciana/.local/lib/python3.6/site-packages (1.0.2)\n",
      "Requirement already satisfied: seaborn in /home/luciana/.local/lib/python3.6/site-packages (0.11.2)\n",
      "Requirement already satisfied: pillow in /home/luciana/.local/lib/python3.6/site-packages (8.4.0)\n",
      "Requirement already satisfied: scikit-learn in /home/luciana/.local/lib/python3.6/site-packages (0.24.2)\n",
      "Requirement already satisfied: ipywidgets in /home/luciana/.local/lib/python3.6/site-packages (from jupyter) (7.7.5)\n",
      "Requirement already satisfied: nbconvert in /home/luciana/.local/lib/python3.6/site-packages (from jupyter) (6.0.7)\n",
      "Requirement already satisfied: jupyter-console in /home/luciana/.local/lib/python3.6/site-packages (from jupyter) (6.4.3)\n",
      "Requirement already satisfied: notebook in /home/luciana/.local/lib/python3.6/site-packages (from jupyter) (6.4.10)\n",
      "Requirement already satisfied: ipykernel in /home/luciana/.local/lib/python3.6/site-packages (from jupyter) (5.5.6)\n",
      "Requirement already satisfied: qtconsole in /home/luciana/.local/lib/python3.6/site-packages (from jupyter) (5.2.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/luciana/.local/lib/python3.6/site-packages (from pandas) (2018.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/luciana/.local/lib/python3.6/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/luciana/.local/lib/python3.6/site-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/luciana/.local/lib/python3.6/site-packages (from sqlalchemy<2.0) (4.8.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/luciana/.local/lib/python3.6/site-packages (from sqlalchemy<2.0) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/luciana/.local/lib/python3.6/site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/luciana/.local/lib/python3.6/site-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/luciana/.local/lib/python3.6/site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/luciana/.local/lib/python3.6/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/luciana/.local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (2.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/luciana/.local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/luciana/.local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/luciana/.local/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/luciana/.local/lib/python3.6/site-packages (from importlib-metadata->sqlalchemy<2.0) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/luciana/.local/lib/python3.6/site-packages (from importlib-metadata->sqlalchemy<2.0) (4.1.1)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /home/luciana/.local/lib/python3.6/site-packages (from ipykernel->jupyter) (4.3.3)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /home/luciana/.local/lib/python3.6/site-packages (from ipykernel->jupyter) (7.16.3)\n",
      "Requirement already satisfied: ipython-genutils in /home/luciana/.local/lib/python3.6/site-packages (from ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /home/luciana/.local/lib/python3.6/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /home/luciana/.local/lib/python3.6/site-packages (from ipykernel->jupyter) (7.1.2)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /home/luciana/.local/lib/python3.6/site-packages (from ipywidgets->jupyter) (1.1.4)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.4 in /home/luciana/.local/lib/python3.6/site-packages (from ipywidgets->jupyter) (3.6.4)\n",
      "Requirement already satisfied: pygments in /home/luciana/.local/lib/python3.6/site-packages (from jupyter-console->jupyter) (2.14.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/luciana/.local/lib/python3.6/site-packages (from jupyter-console->jupyter) (3.0.36)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/luciana/.local/lib/python3.6/site-packages (from nbconvert->jupyter) (0.4)\n",
      "Requirement already satisfied: nbformat>=4.4 in /home/luciana/.local/lib/python3.6/site-packages (from nbconvert->jupyter) (5.1.3)\n",
      "Requirement already satisfied: jupyter-core in /home/luciana/.local/lib/python3.6/site-packages (from nbconvert->jupyter) (4.9.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/luciana/.local/lib/python3.6/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: bleach in /home/luciana/.local/lib/python3.6/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/luciana/.local/lib/python3.6/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/luciana/.local/lib/python3.6/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: testpath in /home/luciana/.local/lib/python3.6/site-packages (from nbconvert->jupyter) (0.6.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (2.10)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/luciana/.local/lib/python3.6/site-packages (from nbconvert->jupyter) (0.5.9)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/luciana/.local/lib/python3.6/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/luciana/.local/lib/python3.6/site-packages (from notebook->jupyter) (25.0.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/luciana/.local/lib/python3.6/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/luciana/.local/lib/python3.6/site-packages (from notebook->jupyter) (1.8.2)\n",
      "Requirement already satisfied: prometheus-client in /home/luciana/.local/lib/python3.6/site-packages (from notebook->jupyter) (0.16.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /home/luciana/.local/lib/python3.6/site-packages (from notebook->jupyter) (1.5.6)\n",
      "Requirement already satisfied: argon2-cffi in /home/luciana/.local/lib/python3.6/site-packages (from notebook->jupyter) (21.3.0)\n",
      "Requirement already satisfied: qtpy in /home/luciana/.local/lib/python3.6/site-packages (from qtconsole->jupyter) (2.0.1)\n",
      "Requirement already satisfied: pexpect in /usr/lib/python3/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.0.1)\n",
      "Requirement already satisfied: backcall in /home/luciana/.local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: jedi<=0.17.2,>=0.10 in /home/luciana/.local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in /home/luciana/.local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/luciana/.local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->jupyter) (59.6.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3/dist-packages (from jinja2>=2.4->nbconvert->jupyter) (0.23)\n",
      "Requirement already satisfied: async-generator in /home/luciana/.local/lib/python3.6/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.10)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/luciana/.local/lib/python3.6/site-packages (from nbformat>=4.4->nbconvert->jupyter) (3.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wcwidth in /home/luciana/.local/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess in /usr/lib/python3/dist-packages (from terminado>=0.8.3->notebook->jupyter) (0.5)\n",
      "Requirement already satisfied: dataclasses in /home/luciana/.local/lib/python3.6/site-packages (from argon2-cffi->notebook->jupyter) (0.8)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/luciana/.local/lib/python3.6/site-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: packaging in /home/luciana/.local/lib/python3.6/site-packages (from bleach->nbconvert->jupyter) (21.3)\n",
      "Requirement already satisfied: webencodings in /home/luciana/.local/lib/python3.6/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/luciana/.local/lib/python3.6/site-packages (from jedi<=0.17.2,>=0.10->ipython>=5.0.0->ipykernel->jupyter) (0.7.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/luciana/.local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/luciana/.local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (22.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/luciana/.local/lib/python3.6/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/luciana/.local/lib/python3.6/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyter pandas \"sqlalchemy<2.0\" pymysql seaborn pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexión a la Base y Lectura de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base...\n",
      "Cargando tabla desde CSV: data/shakespeare/paragraphs.csv\n",
      "Cargando tabla desde CSV: data/shakespeare/characters.csv\n",
      "Cargando tabla desde CSV: data/shakespeare/works.csv\n",
      "Cargando tabla desde CSV: data/shakespeare/chapters.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"data\") / \"shakespeare\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_table(table_name, engine):\n",
    "    \"\"\"\n",
    "    Leer la tabla con SQL y guardarla como CSV,\n",
    "    o cargarla desde el CSV si ya existe\n",
    "    \"\"\"\n",
    "    path_table = data_dir / f\"{table_name}.csv\"\n",
    "    if not path_table.exists():\n",
    "        print(f\"Consultando tabla con SQL: {table_name}\")\n",
    "        t0 = time()\n",
    "        df_table = pd.read_sql(f\"SELECT * FROM {table_name}\", engine)\n",
    "        t1 = time()\n",
    "        print(f\"Tiempo: {t1 - t0:.1f} segundos\")\n",
    "\n",
    "        print(f\"Guardando: {path_table}\\n\")\n",
    "        df_table.to_csv(path_table)\n",
    "    else:\n",
    "        print(f\"Cargando tabla desde CSV: {path_table}\")\n",
    "        df_table = pd.read_csv(path_table, index_col=[0])\n",
    "    return df_table\n",
    "\n",
    "\n",
    "print(\"Conectando a la base...\")\n",
    "conn_str = \"mysql+pymysql://guest:relational@relational.fit.cvut.cz:3306/Shakespeare\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# Todos los párrafos de todas las obras\n",
    "df_paragraphs = load_table(\"paragraphs\", engine)\n",
    "\n",
    "df_characters = load_table(\"characters\", engine)\n",
    "\n",
    "df_works = load_table(\"works\", engine)\n",
    "\n",
    "df_chapters = load_table(\"chapters\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ParagraphNum</th>\n",
       "      <th>PlainText</th>\n",
       "      <th>character_id</th>\n",
       "      <th>chapter_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630863</td>\n",
       "      <td>3</td>\n",
       "      <td>[Enter DUKE ORSINO, CURIO, and other Lords; Mu...</td>\n",
       "      <td>1261</td>\n",
       "      <td>18704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630864</td>\n",
       "      <td>4</td>\n",
       "      <td>If music be the food of love, play on;\\nGive m...</td>\n",
       "      <td>840</td>\n",
       "      <td>18704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>630865</td>\n",
       "      <td>19</td>\n",
       "      <td>Will you go hunt, my lord?</td>\n",
       "      <td>297</td>\n",
       "      <td>18704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630866</td>\n",
       "      <td>20</td>\n",
       "      <td>What, Curio?</td>\n",
       "      <td>840</td>\n",
       "      <td>18704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630867</td>\n",
       "      <td>21</td>\n",
       "      <td>The hart.</td>\n",
       "      <td>297</td>\n",
       "      <td>18704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35460</th>\n",
       "      <td>666323</td>\n",
       "      <td>3460</td>\n",
       "      <td>That she is living,\\nWere it but told you, sho...</td>\n",
       "      <td>866</td>\n",
       "      <td>19648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35461</th>\n",
       "      <td>666324</td>\n",
       "      <td>3467</td>\n",
       "      <td>You gods, look down\\nAnd from your sacred vial...</td>\n",
       "      <td>584</td>\n",
       "      <td>19648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35462</th>\n",
       "      <td>666325</td>\n",
       "      <td>3475</td>\n",
       "      <td>There's time enough for that;\\nLest they desir...</td>\n",
       "      <td>866</td>\n",
       "      <td>19648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35463</th>\n",
       "      <td>666326</td>\n",
       "      <td>3483</td>\n",
       "      <td>O, peace, Paulina!\\nThou shouldst a husband ta...</td>\n",
       "      <td>667</td>\n",
       "      <td>19648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35464</th>\n",
       "      <td>666327</td>\n",
       "      <td>3504</td>\n",
       "      <td>[Exeunt]</td>\n",
       "      <td>1261</td>\n",
       "      <td>19648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35465 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  ParagraphNum  \\\n",
       "0      630863             3   \n",
       "1      630864             4   \n",
       "2      630865            19   \n",
       "3      630866            20   \n",
       "4      630867            21   \n",
       "...       ...           ...   \n",
       "35460  666323          3460   \n",
       "35461  666324          3467   \n",
       "35462  666325          3475   \n",
       "35463  666326          3483   \n",
       "35464  666327          3504   \n",
       "\n",
       "                                               PlainText  character_id  \\\n",
       "0      [Enter DUKE ORSINO, CURIO, and other Lords; Mu...          1261   \n",
       "1      If music be the food of love, play on;\\nGive m...           840   \n",
       "2                             Will you go hunt, my lord?           297   \n",
       "3                                           What, Curio?           840   \n",
       "4                                              The hart.           297   \n",
       "...                                                  ...           ...   \n",
       "35460  That she is living,\\nWere it but told you, sho...           866   \n",
       "35461  You gods, look down\\nAnd from your sacred vial...           584   \n",
       "35462  There's time enough for that;\\nLest they desir...           866   \n",
       "35463  O, peace, Paulina!\\nThou shouldst a husband ta...           667   \n",
       "35464                                           [Exeunt]          1261   \n",
       "\n",
       "       chapter_id  \n",
       "0           18704  \n",
       "1           18704  \n",
       "2           18704  \n",
       "3           18704  \n",
       "4           18704  \n",
       "...           ...  \n",
       "35460       19648  \n",
       "35461       19648  \n",
       "35462       19648  \n",
       "35463       19648  \n",
       "35464       19648  \n",
       "\n",
       "[35465 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlainText</th>\n",
       "      <th>CleanText</th>\n",
       "      <th>CleanContractions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Enter DUKE ORSINO, CURIO, and other Lords; Mu...</td>\n",
       "      <td>enter duke orsino  curio  and other lords  mu...</td>\n",
       "      <td>enter duke orsino  curio  and other lords  mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If music be the food of love, play on;\\nGive m...</td>\n",
       "      <td>if music be the food of love  play on  give me...</td>\n",
       "      <td>if music be the food of love  play on  give me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Will you go hunt, my lord?</td>\n",
       "      <td>will you go hunt  my lord</td>\n",
       "      <td>will you go hunt  my lord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What, Curio?</td>\n",
       "      <td>what  curio</td>\n",
       "      <td>what  curio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The hart.</td>\n",
       "      <td>the hart</td>\n",
       "      <td>the hart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35460</th>\n",
       "      <td>That she is living,\\nWere it but told you, sho...</td>\n",
       "      <td>that she is living  were it but told you  shou...</td>\n",
       "      <td>that she is living  were it but told you  shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35461</th>\n",
       "      <td>You gods, look down\\nAnd from your sacred vial...</td>\n",
       "      <td>you gods  look down and from your sacred vials...</td>\n",
       "      <td>you gods  look down and from your sacred vials...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35462</th>\n",
       "      <td>There's time enough for that;\\nLest they desir...</td>\n",
       "      <td>there's time enough for that  lest they desire...</td>\n",
       "      <td>there's time enough for that  lest they desire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35463</th>\n",
       "      <td>O, peace, Paulina!\\nThou shouldst a husband ta...</td>\n",
       "      <td>o  peace  paulina  thou shouldst a husband tak...</td>\n",
       "      <td>o  peace  paulina  thou shouldst a husband tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35464</th>\n",
       "      <td>[Exeunt]</td>\n",
       "      <td>exeunt</td>\n",
       "      <td>exeunt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35465 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               PlainText  \\\n",
       "0      [Enter DUKE ORSINO, CURIO, and other Lords; Mu...   \n",
       "1      If music be the food of love, play on;\\nGive m...   \n",
       "2                             Will you go hunt, my lord?   \n",
       "3                                           What, Curio?   \n",
       "4                                              The hart.   \n",
       "...                                                  ...   \n",
       "35460  That she is living,\\nWere it but told you, sho...   \n",
       "35461  You gods, look down\\nAnd from your sacred vial...   \n",
       "35462  There's time enough for that;\\nLest they desir...   \n",
       "35463  O, peace, Paulina!\\nThou shouldst a husband ta...   \n",
       "35464                                           [Exeunt]   \n",
       "\n",
       "                                               CleanText  \\\n",
       "0       enter duke orsino  curio  and other lords  mu...   \n",
       "1      if music be the food of love  play on  give me...   \n",
       "2                             will you go hunt  my lord    \n",
       "3                                           what  curio    \n",
       "4                                              the hart    \n",
       "...                                                  ...   \n",
       "35460  that she is living  were it but told you  shou...   \n",
       "35461  you gods  look down and from your sacred vials...   \n",
       "35462  there's time enough for that  lest they desire...   \n",
       "35463  o  peace  paulina  thou shouldst a husband tak...   \n",
       "35464                                            exeunt    \n",
       "\n",
       "                                       CleanContractions  \n",
       "0       enter duke orsino  curio  and other lords  mu...  \n",
       "1      if music be the food of love  play on  give me...  \n",
       "2                             will you go hunt  my lord   \n",
       "3                                           what  curio   \n",
       "4                                              the hart   \n",
       "...                                                  ...  \n",
       "35460  that she is living  were it but told you  shou...  \n",
       "35461  you gods  look down and from your sacred vials...  \n",
       "35462  there's time enough for that  lest they desire...  \n",
       "35463  o  peace  paulina  thou shouldst a husband tak...  \n",
       "35464                                            exeunt   \n",
       "\n",
       "[35465 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Actualizar con su versión de clean_text() de la Tarea_1\n",
    "\n",
    "def clean_text(df, column_name):\n",
    "    # Convertir todo a minúsculas\n",
    "    result = df[column_name].str.lower()\n",
    "\n",
    "    # Quitar signos de puntuación y cambiarlos por espacios (\" \")\n",
    "    # Se incluyen los signos de puntuación buscados antes (excepto el apóstrofe)\n",
    "    signos = [\"[\", \"\\n\", \",\", \"]\", \".\", \";\", \"?\", \"!\", \":\", \"-\", \"(\", \")\", \"&\",'\"', \"\\t\"]\n",
    "    for punc in signos:\n",
    "        result = result.str.replace(punc, \" \")\n",
    "    return result\n",
    "\n",
    "#def expand_contractions(text):\n",
    "#    out = con.fix(text, slang=False)\n",
    "#    return out\n",
    "\n",
    "# Creamos una nueva columna CleanText a partir de PlainText\n",
    "df_paragraphs[\"CleanText\"] = clean_text(df_paragraphs, \"PlainText\")\n",
    "\n",
    "# Se eliminan las contracciones mediante el uso de contractions.\n",
    "df_paragraphs['CleanContractions'] = df_paragraphs['CleanText'] #.apply(expand_contractions)\n",
    "df_paragraphs['CleanContractions']= df_paragraphs['CleanContractions'].str.lower()\n",
    "\n",
    "# Veamos la diferencia\n",
    "df_paragraphs[[\"PlainText\", \"CleanText\", \"CleanContractions\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanText</th>\n",
       "      <th>CharName</th>\n",
       "      <th>Title</th>\n",
       "      <th>GenreType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>if it be love indeed  tell me how much</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Antony and Cleopatra</td>\n",
       "      <td>Tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>there's beggary in the love that can be reckon'd</td>\n",
       "      <td>Antony</td>\n",
       "      <td>Antony and Cleopatra</td>\n",
       "      <td>Tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>i'll set a bourn how far to be beloved</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Antony and Cleopatra</td>\n",
       "      <td>Tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>then must thou needs find out new heaven  new ...</td>\n",
       "      <td>Antony</td>\n",
       "      <td>Antony and Cleopatra</td>\n",
       "      <td>Tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>grates me  the sum</td>\n",
       "      <td>Antony</td>\n",
       "      <td>Antony and Cleopatra</td>\n",
       "      <td>Tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27583</th>\n",
       "      <td>thou hadst a clarence too  and richard kill'd ...</td>\n",
       "      <td>Queen Margaret</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27585</th>\n",
       "      <td>bear with me  i am hungry for revenge  and now...</td>\n",
       "      <td>Queen Margaret</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27587</th>\n",
       "      <td>i call'd thee then vain flourish of my fortune...</td>\n",
       "      <td>Queen Margaret</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27589</th>\n",
       "      <td>forbear to sleep the nights  and fast the days...</td>\n",
       "      <td>Queen Margaret</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27591</th>\n",
       "      <td>thy woes will make them sharp  and pierce like...</td>\n",
       "      <td>Queen Margaret</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CleanText        CharName  \\\n",
       "2058             if it be love indeed  tell me how much        Cleopatra   \n",
       "2059   there's beggary in the love that can be reckon'd           Antony   \n",
       "2060             i'll set a bourn how far to be beloved        Cleopatra   \n",
       "2061   then must thou needs find out new heaven  new ...          Antony   \n",
       "2064                                 grates me  the sum           Antony   \n",
       "...                                                  ...             ...   \n",
       "27583  thou hadst a clarence too  and richard kill'd ...  Queen Margaret   \n",
       "27585  bear with me  i am hungry for revenge  and now...  Queen Margaret   \n",
       "27587  i call'd thee then vain flourish of my fortune...  Queen Margaret   \n",
       "27589  forbear to sleep the nights  and fast the days...  Queen Margaret   \n",
       "27591  thy woes will make them sharp  and pierce like...  Queen Margaret   \n",
       "\n",
       "                      Title GenreType  \n",
       "2058   Antony and Cleopatra   Tragedy  \n",
       "2059   Antony and Cleopatra   Tragedy  \n",
       "2060   Antony and Cleopatra   Tragedy  \n",
       "2061   Antony and Cleopatra   Tragedy  \n",
       "2064   Antony and Cleopatra   Tragedy  \n",
       "...                     ...       ...  \n",
       "27583           Richard III   History  \n",
       "27585           Richard III   History  \n",
       "27587           Richard III   History  \n",
       "27589           Richard III   History  \n",
       "27591           Richard III   History  \n",
       "\n",
       "[626 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos personajes, obras y géneros en el mismo dataset\n",
    "df_dataset = df_paragraphs.merge(df_chapters.set_index(\"id\")[\"work_id\"], left_on=\"chapter_id\", right_index=True)\n",
    "df_dataset = df_dataset.merge(df_works.set_index(\"id\")[[\"Title\", \"GenreType\"]], left_on=\"work_id\", right_index=True)\n",
    "df_dataset = df_dataset.merge(df_characters.set_index('id')[\"CharName\"], left_on=\"character_id\", right_index=True).sort_index()\n",
    "df_dataset = df_dataset[[\"CleanText\", \"CharName\", \"Title\", \"GenreType\"]]\n",
    "\n",
    "# Usaremos sólo estos personajes\n",
    "characters = [\"Antony\", \"Cleopatra\", \"Queen Margaret\"]\n",
    "df_dataset = df_dataset[df_dataset[\"CharName\"].isin(characters)]\n",
    "\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Antony            253\n",
       "Cleopatra         204\n",
       "Queen Margaret    169\n",
       "Name: CharName, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Párrafos por cada personaje seleccionado\n",
    "df_dataset[\"CharName\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset y Features de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dataset[\"CleanText\"].to_numpy()\n",
    "y = df_dataset[\"CharName\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Partir train/test 30% estratificados\n",
    "# -> Definir X_train, X_test, y_train, y_test\n",
    "\n",
    "# X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataSet: 626\n",
      "Tamaños de Train/Test: 438/188\n",
      "Porcentaje Test: 30.03 %\n"
     ]
    }
   ],
   "source": [
    "# Chequeo tamaño de test del 30%\n",
    "print(f\"Tamaño DataSet: {len(X)}\")\n",
    "print(f\"Tamaños de Train/Test: {len(X_train)}/{len(X_test)}\")\n",
    "print(f\"Porcentaje Test: {'{0:.2f}'.format(len(X_test)*100/len(X))} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleopatra : 204\n",
      "Porcentaje Character Cleopatra:  32.59 %\n",
      "Antony : 253\n",
      "Porcentaje Character Antony:  40.42 %\n",
      "Queen Margaret : 169\n",
      "Porcentaje Character Queen Margaret:  27.00 %\n"
     ]
    }
   ],
   "source": [
    "# Párrafos por cada personaje seleccionado\n",
    "df_dataset[\"CharName\"].value_counts()\n",
    "totalSize = len(X)\n",
    "totalCharacters = dict(Counter(df_dataset[\"CharName\"]))\n",
    "\n",
    "for key, value in totalCharacters.items():\n",
    "    print(f\"{key} : {value}\")\n",
    "    p = '{0:.2f}'.format(int(value)*100/totalSize)\n",
    "    print(f\"Porcentaje Character {key}:  {p} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antony : 177\n",
      "Porcentaje en muestra Character Antony:  40.41 %\n",
      "Cleopatra : 143\n",
      "Porcentaje en muestra Character Cleopatra:  32.65 %\n",
      "Queen Margaret : 118\n",
      "Porcentaje en muestra Character Queen Margaret:  26.94 %\n"
     ]
    }
   ],
   "source": [
    "# Chequeo muestreoestratificado (propociones de personajes se mantengan en conjunto de entrenamiento)\n",
    "me_y_train = dict(Counter(y_train))\n",
    "for key, value in me_y_train.items():\n",
    "    print(f\"{key} : {value}\")\n",
    "    p = '{0:.2f}'.format(int(value)*100/(len(X_train)))\n",
    "    print(f\"Porcentaje en muestra Character {key}:  {p} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chequeo muestreoestratificado (propociones de personajes se mantengan en conjunto de test)\n",
    "me_y_test = dict(Counter(y_test))\n",
    "for key, value in me_y_test.items():\n",
    "    print(f\"{key} : {value}\")\n",
    "    p = '{0:.2f}'.format(int(value)*100/(len(X_test)))\n",
    "    print(f\"Porcentaje en test Character {key}:  {p} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conteo de palabras y TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<438x2800 sparse matrix of type '<class 'numpy.longlong'>'\n",
       "\twith 10653 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words=None, ngram_range=(1,1))\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<438x2800 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10653 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfTransformer(use_idf=False)\n",
    "X_train_tf = tf_idf.fit_transform(X_train_counts)\n",
    "X_train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reductor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-10d3a55a483b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Transformar train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_red\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreductor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reductor' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Realizar PCA sobre los datos de entrenamiento\n",
    "# reductor = ...\n",
    "\n",
    "# Transformar train\n",
    "X_train_red = reductor.fit_transform(X_train_tf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de las dos primeras componentes de PCA\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for character in np.unique(y_train):\n",
    "    mask_train = y_train == character\n",
    "    ax.scatter(X_train_red[mask_train, 0], X_train_red[mask_train, 1], label=character)\n",
    "\n",
    "ax.set_title(\"PCA por personaje\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bayes_clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "\n",
    "# Ver las primeras 10 predicciones de train\n",
    "y_pred_train = bayes_clf.predict(X_train_tf)\n",
    "y_pred_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_true, y_pred):\n",
    "    return (y_true == y_pred).sum() / len(y_true)\n",
    "\n",
    "get_accuracy(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Predecir para test y ver la matriz de confusión, y reportar accuracy\n",
    "\n",
    "# X_test_counts = ...\n",
    "# X_test_tfidf = ...\n",
    "# y_test_pred = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de hiper-parámetros con Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# TODO: Agregar más variantes de parámetros que les parezcan relevantes\n",
    "param_sets = [{\"stop_words\": None, \"ngram\": (1,2), \"idf\": True},\n",
    "             {\"stop_words\": None, \"ngram\": (1,1), \"idf\": False}]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Ahora usaremos train/validation/test\n",
    "# Por lo tanto le renombramos train+validation = dev(elopment) dataset\n",
    "X_dev = X_train\n",
    "y_dev = y_train\n",
    "\n",
    "# # Para evitar errores\n",
    "# del X_train\n",
    "# del y_train\n",
    "\n",
    "for params in param_sets:\n",
    "    \n",
    "    # Transormaciones a aplicar (featurizers)\n",
    "    count_vect = CountVectorizer(stop_words=params[\"stop_words\"], ngram_range=params[\"ngram\"])\n",
    "    tf_idf = TfidfTransformer(use_idf=params[\"idf\"])\n",
    "    \n",
    "    for train_idxs, val_idxs in skf.split(X_dev, y_dev):\n",
    "        \n",
    "        # Train y validation para el split actual\n",
    "        X_train_ = X_dev[train_idxs]\n",
    "        y_train_ = y_dev[train_idxs]\n",
    "        X_val = X_dev[val_idxs]\n",
    "        y_val = y_dev[val_idxs]\n",
    "        \n",
    "        # Ajustamos y transformamos Train\n",
    "        X_train_counts = count_vect.fit_transform(X_train_)\n",
    "        X_train_tf = tf_idf.fit_transform(X_train_counts)\n",
    "        \n",
    "        # TODO: Completar el código para entrenar y evaluar \n",
    "        \n",
    "        # Entrenamos con Train\n",
    "        # bayes_clf = ...\n",
    "\n",
    "        # Transformamos Validation\n",
    "        # X_val_counts = ...\n",
    "        # X_val_tfidf = ...\n",
    "        \n",
    "        # Predecimos y evaluamos en Validation\n",
    "        y_pred_val = bayes_clf.predict(X_val_tfidf)\n",
    "        acc = get_accuracy(y_val, y_pred_val)\n",
    "        print(f\"{acc=:.4f} {params=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Opcional) Comparativa con Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "y_train_s = np.char.replace(y_train.astype(str), \" \", \"_\").astype(object)\n",
    "y_test_s = np.char.replace(y_test.astype(str), \" \", \"_\").astype(object)\n",
    "\n",
    "# Convertimos al formato de fasttext: archivo de texto donde cada línea es:\n",
    "# __label__<label> TEXTO\n",
    "Xytrains = \"__label__\" + y_train_s.astype(object) + \" \" + X_train\n",
    "Xytests = \"__label__\" + y_test_s.astype(object) + \" \" + X_test\n",
    "np.savetxt(data_dir / \"train.txt\", Xytrains, fmt=\"%s\")\n",
    "np.savetxt(data_dir / \"test.txt\", Xytests, fmt=\"%s\")\n",
    "\n",
    "Xytests[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=str(data_dir / \"train.txt\"), epoch=100, wordNgrams=2)\n",
    "model.test(str(data_dir / \"test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = model.predict(list(X_test))\n",
    "y_pred_test = [y[0].replace(\"__label__\", \"\") for y in y_out[0]]\n",
    "    \n",
    "print(get_accuracy(y_test_s, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
